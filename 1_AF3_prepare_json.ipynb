{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad48fee3-5fcd-44be-b4bb-ec2310de6af3",
   "metadata": {
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1729791854843,
     "user": {
      "displayName": "Bao, Zhenghong",
      "userId": "15807607380134599325"
     },
     "user_tz": 240
    },
    "id": "ad48fee3-5fcd-44be-b4bb-ec2310de6af3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, copy\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c746ea-0ae4-4d7f-8de1-6c9a810b6917",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "074bd752-b9e5-4676-a7b9-5c0ea95d43f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fa_to_dict(fa_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    convert a fasta file into a python dictionary\n",
    "    input: fasta file\n",
    "    output: python dict\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize some storages\n",
    "    file_items = [] # empty list to store all items read from a fasta file, for easy checking the end of the file\n",
    "    seqNMs = [] # empty list to store sequence headers\n",
    "    seqs = [] # empty list to store sequences\n",
    "    seq = \"\" # empty string to concatinate all lines of a sequence\n",
    "    \n",
    "    # open fasta file\n",
    "    with open(fa_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip() # remove the \"\\n\" empty line\n",
    "            file_items.append(line) # collect all none-empty lines \n",
    "\n",
    "    for i in range(len(file_items)): # using index to easily check the end of the list\n",
    "        \n",
    "        # if the line starts with \">\", this line is a header\n",
    "        if file_items[i][:1] == \">\":\n",
    "            # store the sequence name/header. Change to fit your needs!\n",
    "            # example: \">EGX35_RS00135.1 response regulator transcription factor 28084:28705\" --> \"EGX35_RS00135\"\n",
    "            # example: \">orange1.1g019260m\" --> \"orange1\"\n",
    "            # example: \">orange1.1g014581m\" --> \"orange1\"\n",
    "            \n",
    "            seqNMs.append(file_items[i][1:].split(\" \")[0].split(\"|\")[0]) # remove \">\" and \" \" or \"|\" for the case of alphafoldserver.com\n",
    "            \n",
    "            # store the previous sequence\n",
    "            if seq: # avoid saving the empty string when i=0 at the first header\n",
    "                seqs.append(seq)\n",
    "            seq = \"\"\n",
    "            \n",
    "        # if the line does not start with \">\", this line is a sequence line\n",
    "        else:\n",
    "            seq = seq + file_items[i]\n",
    "            \n",
    "        # if i reached the end, append the last seq, which couldn't be appended during the first if statement\n",
    "        if i == len(file_items) -1 :\n",
    "            seqs.append(seq) \n",
    "    \n",
    "    # convert two lists to a dictionary\n",
    "    dic = dict(zip(seqNMs, seqs))\n",
    "    \n",
    "    return dic\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0346c8e-9702-4400-9ba5-e4fa9631dfa7",
   "metadata": {},
   "source": [
    "## 2. Prepare json files for AlphaFold3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dd1a52c-f56c-4ce8-b7c9-f5954d2e87e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_json(fa1_path, fa2_path=None, n=20, out_dir=\"./\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    prepare json files that contains pairs of 2 proteins for AF3 on both alphafoldserver.com and HiPerGator\n",
    "    \n",
    "    4 input parameters: \n",
    "        1) one fasta file for all possible combinations of pair of 2 proteins\n",
    "        2) or two fasta files for all vs all pairing of 2 proteins\n",
    "        3) n is the number of pairs in a json file, it is recommended as 20 for alphafoldserver.com, <300 for HiPerGator due to the GPU time limitation (14 days)\n",
    "        4) out_dir is where you want to save the prepared json files\n",
    "           \n",
    "    output: json files. Each json file has at most n pairs of 2-proteins.\n",
    "    \"\"\"\n",
    "    # get the protein dictionary of fasta file1\n",
    "    proteins1 = fa_to_dict(fa1_path)\n",
    "    proteins1_keys = list(proteins1.keys())\n",
    "\n",
    "    # get the stems of fasta file names for naming json files\n",
    "    fa1_stem = fa1_path.split(\"/\")[-1].rsplit(\".\", 1)[0] # rsplit(separator, maxsplit). maxsplit=1, will return a list with 2 elements!\n",
    "    fa2_stem = \"\"\n",
    "    \n",
    "    # if fasta file2 is avaiable\n",
    "    if fa2_path:\n",
    "        proteins2 = fa_to_dict(fa2_path)\n",
    "        proteins2_keys = list(proteins2.keys())\n",
    "        fa2_stem = fa2_path.split(\"/\")[-1].rsplit(\".\", 1)[0]\n",
    "    \n",
    "    # helpers\n",
    "    data = [] # empty list to store final results\n",
    "    counter = 0 # determine when to save a json file \n",
    "    \n",
    "    \n",
    "    # n pairs of 2 proteins in a json file\n",
    "    for i in range(len(proteins1)):\n",
    "        \n",
    "        if fa2_path:\n",
    "            start = 0\n",
    "            end = len(proteins2)\n",
    "            prt2 = proteins2\n",
    "            prt2_keys = proteins2_keys\n",
    "        else:\n",
    "            start = i\n",
    "            end = len(proteins1)\n",
    "            prt2 = proteins1\n",
    "            prt2_keys = proteins1_keys\n",
    "            \n",
    "        # 3 updates\n",
    "        for j in range(start, end):\n",
    "            \n",
    "            counter += 1\n",
    "                \n",
    "            # create a template dictionary to store protein-protein pair\n",
    "            temp = {'name': 'protein1_protein2',\n",
    "                    'modelSeeds': [2025],\n",
    "                    'sequences': [{'proteinChain': {'sequence': 'ATCG', 'count': 1}},\n",
    "                                  {'proteinChain': {'sequence': 'ATCG', 'count': 1}}\n",
    "                                 ]\n",
    "                   }\n",
    "\n",
    "            # update job name\n",
    "            temp[\"name\"]= proteins1_keys[i] + \"_\" + prt2_keys[j]\n",
    "\n",
    "            # update the first protein\n",
    "            temp[\"sequences\"][0]['proteinChain']['sequence'] = proteins1[proteins1_keys[i]]\n",
    "\n",
    "            # update the second protein\n",
    "            temp[\"sequences\"][1]['proteinChain']['sequence'] = prt2[prt2_keys[j]]\n",
    "\n",
    "            # add to the final list\n",
    "            data.append(temp)\n",
    "            \n",
    "            \n",
    "            # Going to save json file with all items been updated\n",
    "            # get the date today for dir and joson file name\n",
    "            today = dt.date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "            # create a folder if not exist\n",
    "            new_dir = os.path.join(out_dir, f\"{today}_af3_jsons\")\n",
    "            os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "            # if the data list stored n items, save as a json file\n",
    "            if len(data) == n:\n",
    "                path = f\"{new_dir}/{today}_{fa1_stem}_{fa2_stem}-{counter//n}.json\"\n",
    "                with open(path, \"w\") as jsonFile:\n",
    "                    json.dump(data, jsonFile)\n",
    "                data = [] # reset the result list!\n",
    "            \n",
    "            # elif i and j reached the ends\n",
    "            elif (i == len(proteins1) - 1) & (j == end - 1):\n",
    "                if data:\n",
    "                    path = f\"{new_dir}/{today}_{fa1_stem}_{fa2_stem}-{counter//n + 1}.json\"\n",
    "                    with open(path, \"w\") as jsonFile:\n",
    "                        json.dump(data, jsonFile)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8827f21-8479-4097-b94a-82950df2a715",
   "metadata": {},
   "source": [
    "## one fasta file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeafa95e-0fd4-46b7-8d9d-3200cfdb65b7",
   "metadata": {},
   "source": [
    "prepare json files from ONE fasta file. Each json file contains at most 20 protein-protein pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8195f612-236d-45e4-a3f1-25775afb7be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prep_json(\"BDM_complex.fa\", out_dir = \"BDM_20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae97b50-5e56-4ed2-912c-b4bf20d707a6",
   "metadata": {},
   "source": [
    "prepare json files from ONE fasta file. Each json file contains at most 40 protein-protein pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56d17ff3-6d1e-44eb-a0c7-e49955ec3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_json(\"ZCY_complex.fa\", n=40, out_dir = \"ZCY_40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2264e7-b032-4879-9187-ebc7926a0536",
   "metadata": {},
   "source": [
    "## two fasta files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d52684-1070-4fd7-9f27-2a497936d2b3",
   "metadata": {},
   "source": [
    "prepare json files from TWO fasta files. Each json file contains at most 20 protein-protein pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e35af9e-3df3-4aee-be3a-a8e83dc31e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prep_json(\"BDM_complex.fa\", \"ZCY_complex.fa\", n=20, out_dir = \"BDM_ZCY_20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ddc7d-ca22-401f-a3d2-b6a9bc33967e",
   "metadata": {},
   "source": [
    "prepare json files from TWO fasta files. Each json file contains at most 100 protein-protein pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebf4c0ca-0aaa-427e-968f-96db4f90d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_json(\"BDM_complex.fa\", \"ZCY_complex.fa\", n=100, out_dir = \"BDM_ZCY_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729ca12-f1ab-4291-9db2-9e68c2280994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Yolo-v8",
   "language": "python",
   "name": "yolo-v8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
